{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchquad import  enable_cuda, VEGAS\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ID = 3\n",
    "dataset_name = 'power'\n",
    "\n",
    "\"\"\" network parameters \"\"\"\n",
    "hidden_features = 108\n",
    "num_flow_steps = 6\n",
    "\n",
    "flow_id = 1\n",
    "\n",
    "features = 6\n",
    "\n",
    "REUSE_FROM_FILE = True\n",
    "\"\"\" Change it to your own path \"\"\"\n",
    "REUSE_FILE_PATH = '/home/jiayi/disk/gits/Jupyters/FACE-June-Release/train/'\n",
    "\n",
    "\"\"\" query settings\"\"\"\n",
    "query_seed = 45\n",
    "QUERY_CNT = 2000\n",
    "\n",
    "\"\"\" detailed network parameters\"\"\"\n",
    "anneal_learning_rate = True\n",
    "base_transform_type = 'rq-coupling'\n",
    "\n",
    "dropout_probability = 0\n",
    "grad_norm_clip_value = 5.\n",
    "linear_transform_type='lu'\n",
    "\n",
    "num_bins = 8\n",
    "num_training_steps = 400000\n",
    "num_transform_blocks = 2\n",
    "seed = 1638128\n",
    "tail_bound = 3\n",
    "use_batch_norm = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, sys\n",
    "\n",
    "\"\"\" set GPU first \"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(GPU_ID)\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from time import sleep\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\"\"\" Change it to your own path \"\"\"\n",
    "sys.path.append(os.path.abspath(\"/home/jiayi/disk/gits/Jupyters/FACE-June-Release/utils\"))\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from nflows import transforms\n",
    "from nflows import distributions\n",
    "from nflows import utils\n",
    "from nflows import flows\n",
    "import nflows.nn as nn_\n",
    "\n",
    "\n",
    "\n",
    "import dataUtils as ut\n",
    "\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "DEVICENAME = torch.cuda.get_device_name(0)\n",
    "print('DEVICE NAME\\n', DEVICENAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_transform():\n",
    "    if linear_transform_type == 'permutation':\n",
    "        return transforms.RandomPermutation(features=features)\n",
    "    elif linear_transform_type == 'lu':\n",
    "        return transforms.CompositeTransform([\n",
    "            transforms.RandomPermutation(features=features),\n",
    "            transforms.LULinear(features, identity_init=True)\n",
    "        ])\n",
    "    elif linear_transform_type == 'svd':\n",
    "        return transforms.CompositeTransform([\n",
    "            transforms.RandomPermutation(features=features),\n",
    "            transforms.SVDLinear(features, num_householder=10, identity_init=True)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "def create_base_transform(i):\n",
    "    # tmp_mask = utils.create_alternating_binary_mask(features, even=(i % 2 == 0))\n",
    "    return transforms.coupling.PiecewiseRationalQuadraticCouplingTransform(\n",
    "        mask=utils.create_alternating_binary_mask(features, even=(i % 2 == 0)),\n",
    "        transform_net_create_fn=lambda in_features, out_features: nn_.nets.ResidualNet(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            hidden_features=hidden_features,\n",
    "            context_features=None,\n",
    "            num_blocks=num_transform_blocks,\n",
    "            activation=F.relu,\n",
    "            dropout_probability=dropout_probability,\n",
    "            use_batch_norm=use_batch_norm\n",
    "        ),\n",
    "        num_bins=num_bins,\n",
    "        tails='linear',\n",
    "        tail_bound=tail_bound,\n",
    "        apply_unconditional_transform=True\n",
    "    )\n",
    "\n",
    "\n",
    "# torch.masked_select()\n",
    "def create_transform():\n",
    "    transform = transforms.CompositeTransform([\n",
    "        transforms.CompositeTransform([\n",
    "            create_linear_transform(),\n",
    "            create_base_transform(i)\n",
    "        ]) for i in range(num_flow_steps)\n",
    "    ] + [\n",
    "        create_linear_transform()\n",
    "    ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = distributions.StandardNormal((features,))\n",
    "transform = create_transform()\n",
    "flow = flows.Flow(transform, distribution).to(device)\n",
    "\n",
    "\n",
    "\"\"\" Change it to your own path \"\"\"\n",
    "if 'Ti' in DEVICENAME:\n",
    "    path = os.path.join('/home/jiayi/disk/gits/Jupyters/FACE-June-Release/train/models/power/',\n",
    "                        '{}-id{}-best-val.t'.format(dataset_name, flow_id))\n",
    "\n",
    "else:\n",
    "    path = os.path.join('/data/jiayi/FACE/ckpts',\n",
    "                                   '{}-best-val-{}.t'.format(dataset_name, timestamp))\n",
    "flow.load_state_dict(torch.load(path))\n",
    "\n",
    "flow.cuda()\n",
    "flow.eval()\n",
    "\n",
    "\n",
    "n_params = utils.get_num_parameters(flow)\n",
    "print('There are {} trainable parameters in this model.'.format(n_params))\n",
    "print('Parameters total size is {} MB'.format(n_params * 4 / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DataWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, n, dim = ut.LoadTable(dataset_name)\n",
    "DW = ut.DataWrapper(data, dataset_name)\n",
    "rng = np.random.RandomState(query_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(query_seed)\n",
    "queries = DW.generateNQuery(2000, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load oracle_cards\"\"\"\n",
    "oracle_cards = ut.LoadOracleCardinalities(dataset_name, query_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_lists = DW.getLegalRangeNQuery(queries)\n",
    "legal_tensors = torch.Tensor(legal_lists).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchquad import set_up_backend\n",
    "set_up_backend(\"torch\", data_type=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" q-error \"\"\"\n",
    "def ErrorMetric(est_card, card):\n",
    "    if isinstance(est_card, torch.FloatTensor) or isinstance(est_card, torch.IntTensor):\n",
    "        est_card = est_card.cpu().detach().numpy()\n",
    "    if isinstance(est_card, torch.Tensor):\n",
    "        est_card = est_card.cpu().detach().numpy()\n",
    "    est_card = np.float(est_card)\n",
    "    card = np.float(card)\n",
    "    if card == 0 and est_card != 0:\n",
    "        return est_card\n",
    "    if card != 0 and est_card == 0:\n",
    "        return card\n",
    "    if card == 0 and est_card == 0:\n",
    "        return 1.0\n",
    "    return max(est_card / card, card / est_card)\n",
    "\n",
    "def BatchErrorMetrix(est_list, oracle_list):\n",
    "    ret = np.zeros(len(est_list))\n",
    "    ID = 0\n",
    "    for est, real in zip(est_list, oracle_list):\n",
    "        ret[ID] = ErrorMetric(est, real)\n",
    "        ID = ID + 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_batch_time = 0\n",
    "def f_batch(inp):\n",
    "    global f_batch_time\n",
    "    with torch.no_grad():\n",
    "        inp = inp.cuda()\n",
    "\n",
    "        print(\"【Example input】\", inp[0,:])\n",
    "        print(\"inp shape \", inp.shape)\n",
    "        st = time.time()\n",
    "        prob_list = flow.log_prob(inp)\n",
    "        prob_list = torch.exp(prob_list)\n",
    "        print(\"【max_prob】 \",prob_list.max())\n",
    "        print(\"【median_prob】 \",prob_list.median())\n",
    "        en = time.time()\n",
    "        f_batch_time += en - st\n",
    "\n",
    "        return prob_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __init__(self, activated=True):\n",
    "        self.activated = activated\n",
    "        self.original_stdout = None\n",
    "\n",
    "    def open(self):\n",
    "        \"\"\" no output \"\"\"\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self.original_stdout\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\" output \"\"\"\n",
    "        self.original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __enter__(self):\n",
    "        if self.activated:\n",
    "            self.close()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.activated:\n",
    "            self.open()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse Sampling Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# f=open('/home/jiayi/disk/FACE/map.pickle','wb')  \n",
    "# pickle.dump(target_map, f)\n",
    "if REUSE_FROM_FILE == True:\n",
    "    f=open(REUSE_FILE_PATH + '{}.pickle'.format(dataset_name),'rb')  \n",
    "    target_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = DW.getLegalRangeQuery([[],[],[]])\n",
    "z = torch.Tensor(z)\n",
    "print(z.shape)\n",
    "full_integration_domain = torch.Tensor(z)\n",
    "\n",
    "domain_starts = full_integration_domain[:, 0]\n",
    "domain_sizes =  full_integration_domain[:, 1] - domain_starts\n",
    "domain_volume = torch.prod(domain_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if REUSE_FROM_FILE == False:\n",
    "    vegas = VEGAS()\n",
    "    bigN = 1000000 * 40\n",
    "\n",
    "    st = time.time()\n",
    "    result = vegas.integrate(f_batch,dim=features,\n",
    "                             N=bigN,\n",
    "                             integration_domain=full_integration_domain,\n",
    "                             use_warmup=True,\n",
    "                             use_grid_improve=True,\n",
    "                             max_iterations=40\n",
    "                             )\n",
    "\n",
    "    en= time.time()\n",
    "    print(\"Took \", en-st)\n",
    "    print(result)\n",
    "    result = result * DW.n\n",
    "\n",
    "    print('result is ',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REUSE_FROM_FILE == False:\n",
    "    target_map = vegas.map\n",
    "    import pickle\n",
    "    f=open(REUSE_FILE_PATH + \"{}.pickle\".format(dataset_name),'wb')  \n",
    "    pickle.dump(target_map, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchquad import BatchMulVEGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(n, N, num_iterations=3, alpha=0.5, beta=0.5):\n",
    "    global f_batch_time\n",
    "    \"\"\" n: batch size \"\"\"\n",
    "    z = BatchMulVEGAS()\n",
    "    DIM = features\n",
    "    full_integration_domain = torch.Tensor(DIM * [[0,1]])\n",
    "    \n",
    "    start_id = 0\n",
    "    end_id = 0\n",
    "\n",
    "    f_batch_time  = 0\n",
    "    st = time.time()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        while start_id < 2000:\n",
    "            end_id = end_id + n\n",
    "            if end_id > 2000:\n",
    "                end_id = 2000\n",
    "            z.setValues(f_batch,\n",
    "                    dim=DIM,\n",
    "                    alpha=alpha,\n",
    "                    beta=beta,\n",
    "                    N=N,\n",
    "                    n=end_id - start_id,\n",
    "                    iterations=num_iterations,\n",
    "                    integration_domains=legal_tensors[start_id:end_id],\n",
    "                    rng=None,\n",
    "                    seed=234,\n",
    "                    reuse_sample_points=True,\n",
    "                    target_map=target_map,\n",
    "                    target_domain_starts = domain_starts,\n",
    "                    target_domain_sizes = domain_sizes,\n",
    "                    )\n",
    "            start_id = start_id + n\n",
    "            results.append(z.integrate())\n",
    "\n",
    "    en = time.time()\n",
    "    total_time = en-st\n",
    "    return total_time, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end-to-end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testHyper(n, N, num_iterations, alpha, beta):\n",
    "    with HiddenPrints():\n",
    "        total_time, result = getResult(n=n, \n",
    "                               N=N, \n",
    "                               num_iterations=num_iterations,\n",
    "                               alpha=alpha, \n",
    "                               beta=beta)\n",
    "    \n",
    "\n",
    "        result = torch.cat(tuple(result))\n",
    "        FULL_SIZE = torch.Tensor([DW.n])\n",
    "        result = result * FULL_SIZE\n",
    "        result = result.to('cpu')\n",
    "\n",
    "        n_ = 2000\n",
    "        oracle_list = oracle_cards.copy()\n",
    "\n",
    "        err_list = BatchErrorMetrix(result.int(), oracle_list)\n",
    "\n",
    "\n",
    "        total_query_time = total_time\n",
    "        avg_per_query_time = 1000. * (total_query_time/n_)\n",
    "        avg_f_batch_time   = 1000.* f_batch_time / n_\n",
    "        avg_vegas_time     = avg_per_query_time - avg_f_batch_time\n",
    "\n",
    "\n",
    "\n",
    "    print(\"********** total_n=[{}] batchn=[{}]  N=[{}]  nitr=[{}]  alpha=[{}]  beta=[{}] ******\".format(n_, n, N, num_iterations, alpha, beta))\n",
    "    print('@ Average per query          [{}] ms'.format(avg_per_query_time))\n",
    "    print(' --  Average per query NF    [{}] ms'.format(avg_f_batch_time))\n",
    "    print(' --  Average per query vegas [{}] ms'.format(avg_vegas_time))\n",
    "    p50 = np.percentile (err_list, 50)\n",
    "    p95 = np.percentile(err_list, 95)\n",
    "    p99 = np.percentile(err_list, 99)\n",
    "    pmax = np.max(err_list)\n",
    "    print('Median [{:.3f}]  95th [{:.3f}]  99th [{:.3f}]  max [{:.3f}]'.format(np.percentile (err_list, 50), np.percentile(err_list, 95),\n",
    "                                                               np.percentile(err_list, 99), np.max(err_list)))\n",
    "\n",
    "    return p50,p95,p99,pmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha_list= [0.6]\n",
    "beta_list = [0.1]\n",
    "\n",
    "p50s = []\n",
    "p95s = []\n",
    "p99s = []\n",
    "pmaxs = []\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    for beta in beta_list:\n",
    "        p50, p95, p99, pmax = testHyper(667, 15000, 3, alpha, beta)\n",
    "        p95s.append(p95)\n",
    "        p99s.append(p99s)\n",
    "        pmaxs.append(pmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-testenv]",
   "language": "python",
   "name": "conda-env-.conda-testenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
